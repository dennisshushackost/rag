{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipepline from Scratch \n",
    "\n",
    "RAG (Retrieval Augmented Generation) has to goal to take information and pass it to a Large Language Model (LLM) so it can generate outputs based on that information. \n",
    "\n",
    "* **Retrieval**: Find relevant information given a user query. I.e. What are the macronutrients and what do they do -> Retrives any passages of text related to the macronutrients from a nutritien textbook. \n",
    "* **Augmented**: We want to take the relevant information from our data and then augment our imput (prompt) to an LLM with that relevant information. \n",
    "* **Generation**: Take the first two stepes and pass them to an LLM for a good output. \n",
    "\n",
    "Why RAG? \n",
    "The main goal of RAG is to improve the generation output of LLMs.\n",
    "1. Prevent Hallucinations - LLMs are good at generating good looking text, however it may not be factual.\n",
    "RAG can help LLMs create text based on text that is factual. \n",
    "2. Many LLMs are trained on internet data, as such they have a good understanding of language. RAG allows us to use custom data. We can use customer support Q&A for chatting. We can retrieve relevant snippets of text for example. We can retrieve the snippets and then use an LLM to craft an answer from these snippets. \n",
    "3. Why run it locally. We do not have to wait for any transfers. Cost is another big factor. If we own our own hardware, we can save on large amounts of costs. Furthermore, there is no vendor locking, when we run our own software, hardware. If OpenAI or another large internet company shuts down, we can still run the buisness. Privacy - Id you have documentation, maybe you do not want to send it to an API. You want to setup an LLM and run it on your own hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we going to build?\n",
    "https://whimsical.com/simple-local-rag-workflow-39kToR3yNf7E8kY4sS2tjV\n",
    "\n",
    "1. Open a pdf document.\n",
    "2. Format the text of the PDF textbook ready for an embedding model.\n",
    "3. Embed all the chunk of text in the textbook and turn them into numerical representations (embedding) which can store for later. \n",
    "4. Build retrieval system that uses vector search to find the relevant chunks of text based on query. \n",
    "5. Create a prompt that incorperates the retrieved prieces of text. \n",
    "6. Generate the answer to a query based on the passages based on the passages of the textbook with an LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document pre-processing and embedding creation \n",
    "\n",
    "Ingridients: PDF document of choice (could be any kind of document.) and an embedding model of choice. \n",
    "1. Import PDF document\n",
    "2. Process text for embedding (splitting into chunks of sentences)\n",
    "3. Embedd textchunks with embedding model.\n",
    "4. Save embedding to file for later (embeddings will store on file for many years until you loose them on hd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The file already exists\n"
     ]
    }
   ],
   "source": [
    "# Programatically get the pdf document \n",
    "import os \n",
    "import requests \n",
    "\n",
    "# Get PDF document:\n",
    "pdf_path = \"./data/human-nutrition-text.pdf\"\n",
    "\n",
    "# Download the PDF:\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(\"[INFO] File does not exist, downloading....\")\n",
    "\n",
    "    # Enter the URL of the PDF: \n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "\n",
    "    # Local Filename to save the file:\n",
    "    filename = pdf_path\n",
    "\n",
    "    # Send a GET request:\n",
    "    response = requests.get(url=url)\n",
    "\n",
    "    # Check if the request was successfull:\n",
    "    if response.status_code == 200:\n",
    "        # Open file and save it (wb = write binary)\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"[INFO] The file has been downloaded and saved as {filename}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"[INFO] The file already exists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a PDF as such we can open it. We can use PyMUPDF which seems to be the best for PDF reading with the best Text formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # PyMUPDF \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
